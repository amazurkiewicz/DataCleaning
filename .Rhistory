Hello World!
OOPS!
!!!
h
!
devtools
a=3
!
a
a=False
library(swirl)
swirl()
5+7
x <- 5+7
x
y <- x-3
y
c(1.1,9,3.14)
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z*2 + 100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2 + 1000
my_div
getwd()
ls()
x <- 9
ls()
dir()
list.files()
?list.files
args(list.files)
old.dir <- getwd()
dir.create('testdir')
setwd('testdir')
file.create('mytest.R')
list.files()
file.exists('mytest.R')
file.info('mytest.R')
file.rename('mytest.R','mytest2.R')
file.copy('mytest2.R','mytest3.R')
file.path('mytest3.R')
file.path('folder1','folder2')
?dir.create
dir.create('testdir2/testdir3',recursive=TRUE)
dir.create(file.path('testdir2/testdir3'),recursive=TRUE)
dir.create(file.path('testdir2','testdir3'),recursive=TRUE)
?unlink
unlink('testdir2')
unlink('testdir2', recursive=TRUE)
setwd(old.dir)
unlink('testdir',recursive = TRUE)
x
x[1:10]
x[is.na(x)]
x[!is.na(x)]
y <- x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x) & x > 0]
x[3,5,7]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 = c(11,2,NA)
vect2 <- c(11,2,NA)
names(vect2) <- c('foo','bar','norf')
vect
vect2
names(vect)
names(vect2)
identical(vect,vect2)
vect['bar']
vect[c('foo','bar')]
library(datasets)
data(iris)
iris
tapply((iris$Sepal.Length,iris$Species),mean)
tapply(iris$Sepal.Length,iris$Species,mean)
?lapply
?sapply
lapply(iris$Sepal.Length, mean)
apply(split(iris,iris$Species),mean)
?apply
apply(split(iris$Sepal.Length,iris$Species),mean)
sapply(split(iris$Sepal.Length,iris$Species),mean)
apply(iris,2,mean)
apply(iris,1,mean)
apply(iris,1,mean, use.names=TRUE)
apply(iris,2,mean, use.names=TRUE)
colMeans(iris$Sepal.Length)
colMeans(iris)
colMeans(iris[,1:4])
colMeans(iris[,1:5])
colMeans(iris[,1:5])
mapply(function(x,y) x+y, 1:4,2:8:2)
mapply(function(x,y) x+y, 1:4,2:2:8)
mapply(function(x,y) x+y, 1:4,5:8)
tapply(iris,iris$Species,mean)
tapply(iris$Sepal.Width,iris$Species,mean)
tapply(iris$Sepal.Width,iris$Sepal.Length,mean)
split(iris,iris$Species)
lapply(split(iris,iris$Species),mean)
lapply(split(iris$Sepal.Length,iris$Species),mean)
colMeans(split(iris,iris$Species))
colMeans(split(iris$Sepal.Length,iris$Species))
colMeans(split(iris$Sepal.Length,iris$Species))
str(split(iris$Sepal.Length,iris$Species))
interaction(iris$Sepal.Width,iris$Species)
interaction(iris$Sepal.Width,iris$Species, drop=TRUE)
q()
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(file.url, 'q1.csv')
dateDownloaded <- date()
data <- read.csv('q1.csv')
head(data)
str(data)
data$VAL>=1000000
data$VAL
data$VAL==24
sum(data$VAL==24)
sum(data$VAL==24, na.rm = TRUE)
data$FES
head(data$FES)
View(data)
xls.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx'
library(xlxs)
library(xlsx)
?read.xlsx
install.packages("xlsx")
library(xlsx)
download.file(xls.url)
download.file(xls.url,'q3.xlsx')
dateDownloaded <- date()
dat <- read.xlsx('q3.xlsx', sheetIndex = 1, rowIndex = 18:23, colIndex = 7:15)
dat <- read.xlsx('q3.xlsx', sheetIndex = 1, rowIndex = c(18:23), colIndex = c(7:15))
getwd()
dat <- read.xlsx('q3.xlsx', sheetIndex = 1, rowIndex = 18:23, colIndex = 7:15)
install.packages("xlsx", dep=T)
install.packages("xlsx", dep = T)
xls.url
download.file(xls.url,'q3.xlsx',method='curl')
install.packages("curl")
download.file(xls.url,destfile = 'q3.xlsx',method='curl')
download.file(xls.url,destfile = 'q3.xlsx',method='curl')
download.file(xls.url,destfile = 'q3.xlsx')
download.file(url = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx',destfile = 'q3.xlsx')
dateDownloaded <- date(0)
dateDownloaded <- date()
library(xlsx)
dat <- read.xlsx('q3.xlsx',sheetIndex = 1)
wd <- getwd()
list.files(wd)
dat <- read.xlsx('./q3.xlsx',sheetIndex = 1)
gc()
dat <- read.xlsx('./q3.xlsx',sheetIndex = 1)
dat <- read.xlsx('q3.xlsx',sheetIndex = 1)
dat <- read.xlsx2('q3.xlsx',sheetIndex = 1)
download.file(url = 'http://www.gsa.gov/dg/pbs/DATA.gov_NGAP.xlsx',destfile = 'q3.xlsx')
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
swirl()
options(editor = "internal")
swirl()
swirl()
?n
?n_distinct
submit()
pack_sum
?quantile
quantile(pack_sum$count, probs=0.99)
top_counts <- filter(pack_sum, count>679.56)
top_counts <- filter(pack_sum, count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex","class"))
students2
submit()
students3
?gather
submit()
?spread
submit()
extract_numeric("class5")
?mutate
submit()
students4
submit()
submit()
submit()
passed
failed
passed <- mutate(passed, status = "passed")
passed
failed <- mutate(passed, status = "failed")
failed <- mutate(failed, status = "failed")
?bind_rows
library(dplyr)
bind_rows(passed, failed)
sat
submit()
?separate
submit()
submit()
submit()
install.packages("RMySQL")
library(RMySQL)
DB <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(DB, "show databases")
result
dbDisconnect(DB)
result <- dbGetQuery(DB, "show databases")
DB <- dbConnect(MySQL(), user = "python", host = "swissmon1.terra.ch")
?`dbConnect,MySQLConnection-method`
DB <- dbConnect(MySQL(), user = "python", password="nohtyp", host = "swissmon1.terra.ch")
dbGetQuery(DB, "show databases")
dbDisconnect(DB)
con <- url('http://biostat.jhsph.edu/~jleek/contact.html')
html <- readLines(con = con)
html
close(con)
library(XML)
html <- htmlTreeParse('http://biostat.jhsph.edu/~jleek/contact.html', useInternalNodes = T)
html
dim(html)
html[1]
html[[1]]
html <- readLines(url('http://biostat.jhsph.edu/~jleek/contact.html'))
html[1]
sapply(html[c(10,20,30,100)], function(x) nchar(x))
html[10]
html[20]
html[100]
library(httr)
myapp <- oauth_app("github",
key = "coursera",
secret = "62b3412e89bedd4ca69bc7b7244a649aa58ab52c")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github",
key = "amazurkiewicz",
secret = "62b3412e89bedd4ca69bc7b7244a649aa58ab52c")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github",
key = "607cba0f36e63213ca98",
secret = "7b83b118ea676b70e2fb0b456bd87608b3f71884")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
git <- content(req)
git
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(all.data)
df <- data.frame(c(1,1,2,2),c(1,2,1,2),c(1,2,10,20))
df
names(df) <- c('One','Two','Three')
df
aggregate(df$One,by=df$Three,FUN=mean)
aggregate(df$One,by=list(df$Three),FUN=mean)
?split
setwd('C:\\Users\\Alex\\Desktop\\R_Coursera\\data-cleaning\\w4\\w4project\\UCI HAR Dataset')
library(dplyr)
library(data.table)
## Load and Clean Activity Labels
activities <- read.table('activity_labels.txt')
names(activities) <- c('ActivityNumber','Activity')
## Load and clean Features
features <- read.table('features.txt')
names(features) <- c('FeatureNumber','FeatureName')
features$FeatureName <- as.character(features$FeatureName)
## Get indices of mean() and std() features
index.mean <- grep("-mean\\(\\)",features$FeatureName)
index.std <- grep("-std\\(\\)",features$FeatureName)
index.all <- sort(c(index.mean,index.std)) ## Sorted list of indices for mean and std
features <- features[index.all,]
## TEST DATA
## Load Test Data, extracting only columns index.cols (mean() and std())
test.data <- read.table('./test/X_test.txt')[,features$FeatureNumber]
names(test.data) <- features$FeatureName
## Load Test activity info and add to test.data using 'activities'
test.activity <- read.table('./test/y_test.txt')
test.data$ActivityNumber <- test.activity[,]
test.data$Activity <- sapply(test.activity,function(x) x <- activities$Activity[x])
## Load and add Subject Numbers to test.data
subjects.test <- read.table('./test/subject_test.txt')
test.data$SubjectNumber <- subjects.test[,]
test.data$GroupType <- rep('TEST',nrow(test.data))
## TRAIN DATA
## Load Training Data, extracting only columns index.cols (mean() and std())
train.data <- read.table('./train/X_train.txt')[,features$FeatureNumber]
names(train.data) <- features$FeatureName
## Load Test activity info and add to test.data using 'activities'
train.activity <- read.table('./train/y_train.txt')
train.data$ActivityNumber <- train.activity[,]
train.data$Activity <- sapply(train.activity,function(x) x <- activities$Activity[x])
## Load and add Subject Numbers to test.data
subjects.train <- read.table('./train/subject_train.txt')
train.data$SubjectNumber <- subjects.train[,]
train.data$GroupType <- rep('TRAIN',nrow(train.data))
all.data <- data.table(rbind(test.data,train.data[,]))
split(all.data, all.data$SubjectNumber)
subject.data <- split(all.data, all.data$SubjectNumber)
lapply?
?lapply
x <- aggregate(all.data, list(all.data$SubjectNumber,all.data$ActivityNumber), mean)
View(x)
View(x)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
View(avg.data)
source('C:/Users/Alex/Desktop/R_Coursera/data-cleaning/w4/w4project/UCI HAR Dataset/run_analysis.R')
